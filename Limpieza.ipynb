{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "66fbbadb-a009-4b0f-a8f3-7584c22afe88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/oscarperez/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/oscarperez/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "/Users/oscarperez/opt/anaconda3/envs/acobur/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# librerías\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from datasets import Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2c56bbff-5c3a-4d32-b5bb-81af4347f7a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text  \\\n",
      "0                                REPÚBLICA DE COLOMBIA     \n",
      "1                                                          \n",
      "2                                                          \n",
      "3                                                          \n",
      "4                                                          \n",
      "...                                                  ...   \n",
      "47839                               DIANA FAJARDO RIVERA   \n",
      "47840                                         Magistrada   \n",
      "47841  Este documento fue generado con firma electrón...   \n",
      "47842  Código de verificación: aca4c2c8090b666ff40ada...   \n",
      "47843  Verifique este documento electrónico en: https...   \n",
      "\n",
      "                                         NombreArchivo  \n",
      "0                                                 None  \n",
      "1                                                 None  \n",
      "2                                                 None  \n",
      "3                                                 None  \n",
      "4                                                 None  \n",
      "...                                                ...  \n",
      "47839                                             None  \n",
      "47840                                             None  \n",
      "47841                                             None  \n",
      "47842                                             None  \n",
      "47843  D0015639-Auto Rechazo-(2024-01-25 07-04-41).pdf  \n",
      "\n",
      "[47844 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ruta_archivo = 'oraciones.txt'\n",
    "with open(ruta_archivo, 'r', encoding='utf-8') as archivo:\n",
    "    contenido = archivo.read()\n",
    "\n",
    "# Separar el contenido en filas y luego dividir cada fila por el delimitador '\\t'\n",
    "filas = [fila.split('\\t') for fila in contenido.split('\\n') if fila]\n",
    "\n",
    "# Crear un DataFrame a partir de la lista de listas\n",
    "# pandas automáticamente asignará cada elemento de las sublistas a una columna separada\n",
    "df = pd.DataFrame(filas)\n",
    "\n",
    "# Si sabes que siempre habrá 2 columnas, puedes renombrarlas para mayor claridad\n",
    "if len(df.columns) == 2:\n",
    "    df.columns = ['text', 'NombreArchivo']\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a9785a95-2c8c-49f8-ad7d-b1642e7ff358",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dt/wd8bxjhn0_121hnh8db2qth40000gn/T/ipykernel_23525/157975696.py:8: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df['NombreArchivo'] = df['NombreArchivo'].replace('', pd.NA).fillna(method='ffill')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>NombreArchivo</th>\n",
       "      <th>conteo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47843</th>\n",
       "      <td>Verifique este documento electrónico en: https...</td>\n",
       "      <td>D0015639-Auto Rechazo-(2024-01-25 07-04-41).pdf</td>\n",
       "      <td>47843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47842</th>\n",
       "      <td>Código de verificación: aca4c2c8090b666ff40ada...</td>\n",
       "      <td>D0015639-Auto Rechazo-(2024-01-25 07-04-41).pdf</td>\n",
       "      <td>47842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47841</th>\n",
       "      <td>Este documento fue generado con firma electrón...</td>\n",
       "      <td>D0015639-Auto Rechazo-(2024-01-25 07-04-41).pdf</td>\n",
       "      <td>47841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47840</th>\n",
       "      <td>Magistrada</td>\n",
       "      <td>D0015639-Auto Rechazo-(2024-01-25 07-04-41).pdf</td>\n",
       "      <td>47840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47839</th>\n",
       "      <td>DIANA FAJARDO RIVERA</td>\n",
       "      <td>D0015639-Auto Rechazo-(2024-01-25 07-04-41).pdf</td>\n",
       "      <td>47839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47838</th>\n",
       "      <td>Notifíquese y cú mplase.</td>\n",
       "      <td>D0015639-Auto Rechazo-(2024-01-25 07-04-41).pdf</td>\n",
       "      <td>47838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47837</th>\n",
       "      <td>Ejecutoriada esta decisión, archívese el exped...</td>\n",
       "      <td>D0015639-Auto Rechazo-(2024-01-25 07-04-41).pdf</td>\n",
       "      <td>47837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47836</th>\n",
       "      <td>TERCERO.</td>\n",
       "      <td>D0015639-Auto Rechazo-(2024-01-25 07-04-41).pdf</td>\n",
       "      <td>47836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47835</th>\n",
       "      <td>lo previsto por el artículo 6º del Decreto 206...</td>\n",
       "      <td>D0015639-Auto Rechazo-(2024-01-25 07-04-41).pdf</td>\n",
       "      <td>47835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47834</th>\n",
       "      <td>procede el recurso de súplica ante la Sala Ple...</td>\n",
       "      <td>D0015639-Auto Rechazo-(2024-01-25 07-04-41).pdf</td>\n",
       "      <td>47834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "47843  Verifique este documento electrónico en: https...   \n",
       "47842  Código de verificación: aca4c2c8090b666ff40ada...   \n",
       "47841  Este documento fue generado con firma electrón...   \n",
       "47840                                         Magistrada   \n",
       "47839                               DIANA FAJARDO RIVERA   \n",
       "47838                           Notifíquese y cú mplase.   \n",
       "47837  Ejecutoriada esta decisión, archívese el exped...   \n",
       "47836                                           TERCERO.   \n",
       "47835  lo previsto por el artículo 6º del Decreto 206...   \n",
       "47834  procede el recurso de súplica ante la Sala Ple...   \n",
       "\n",
       "                                         NombreArchivo  conteo  \n",
       "47843  D0015639-Auto Rechazo-(2024-01-25 07-04-41).pdf   47843  \n",
       "47842  D0015639-Auto Rechazo-(2024-01-25 07-04-41).pdf   47842  \n",
       "47841  D0015639-Auto Rechazo-(2024-01-25 07-04-41).pdf   47841  \n",
       "47840  D0015639-Auto Rechazo-(2024-01-25 07-04-41).pdf   47840  \n",
       "47839  D0015639-Auto Rechazo-(2024-01-25 07-04-41).pdf   47839  \n",
       "47838  D0015639-Auto Rechazo-(2024-01-25 07-04-41).pdf   47838  \n",
       "47837  D0015639-Auto Rechazo-(2024-01-25 07-04-41).pdf   47837  \n",
       "47836  D0015639-Auto Rechazo-(2024-01-25 07-04-41).pdf   47836  \n",
       "47835  D0015639-Auto Rechazo-(2024-01-25 07-04-41).pdf   47835  \n",
       "47834  D0015639-Auto Rechazo-(2024-01-25 07-04-41).pdf   47834  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['conteo'] = range(len(df))\n",
    "df = df.sort_values(by = 'conteo', ascending = False)\n",
    "\n",
    "# Reemplazar 'None' por espacio vacío en la columna 'NombreArchivo'\n",
    "df['NombreArchivo'] = df['NombreArchivo'].fillna('')\n",
    "\n",
    "# Completar las filas vacías en 'NombreArchivo' con el último valor no vacío\n",
    "df['NombreArchivo'] = df['NombreArchivo'].replace('', pd.NA).fillna(method='ffill')\n",
    "#df = df.sort_values(by = 'conteo', ascending = True)\n",
    "\n",
    "df.to_csv('sentencias.csv', index = False)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b0efe81b-4707-4042-8c38-6b937132d4c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text'],\n",
      "        num_rows: 47844\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Convertir el DataFrame de pandas a un Dataset de Hugging Face\n",
    "texto = df['text'] \n",
    "texto = texto.to_frame()\n",
    "dataset = Dataset.from_pandas(texto)\n",
    "dataset = dataset.remove_columns('__index_level_0__')\n",
    "\n",
    "\n",
    "# Crear un DatasetDict con el Dataset bajo la clave 'train'\n",
    "dataset_dict = DatasetDict({\n",
    "    'train': dataset\n",
    "})\n",
    "\n",
    "print(dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "0578483d-c919-4dd9-861b-2fb0967743d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(sentence_batch):\n",
    "    # extrae el texto de la entrada\n",
    "    text_list = sentence_batch['text']\n",
    "\n",
    "    cleaned_text_list = []\n",
    "    for text in text_list:\n",
    "        # Convierte el texto a minúsculas\n",
    "        text = text.lower()\n",
    "\n",
    "        # Elimina URLs\n",
    "        text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "\n",
    "        # Elimina las menciones @ y '#' de las redes sociales\n",
    "        text = re.sub(r'\\@\\w+|\\#\\w+', '', text)\n",
    "\n",
    "        # Elimina los caracteres de puntuación\n",
    "        text = strip_punctuation(text)\n",
    "\n",
    "        # Elimina los números\n",
    "        text = strip_numeric(text)\n",
    "\n",
    "        # Elimina las palabras cortas\n",
    "        text = strip_short(text,minsize=2)\n",
    "\n",
    "        # Elimina las palabras comunes (stop words)\n",
    "        stop_words = set(stopwords.words('spanish'))\n",
    "        word_tokens = word_tokenize(text)\n",
    "        filtered_text = [word for word in word_tokens if word not in stop_words]\n",
    "\n",
    "        cleaned_text_list.append(filtered_text)\n",
    "\n",
    "    # Devuelve el texto limpio\n",
    "    return {'text': cleaned_text_list}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "e84191ed-51a6-4f10-8f6f-36f9682daf89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|                                     | 0/47844 [00:00<?, ? examples/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'strip_punctuation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[102], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sentences_corpus \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_dict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclean_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/acobur/lib/python3.12/site-packages/datasets/dataset_dict.py:869\u001b[0m, in \u001b[0;36mDatasetDict.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_names, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, desc)\u001b[0m\n\u001b[1;32m    865\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache_file_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    866\u001b[0m     cache_file_names \u001b[38;5;241m=\u001b[39m {k: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m}\n\u001b[1;32m    867\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DatasetDict(\n\u001b[1;32m    868\u001b[0m     {\n\u001b[0;32m--> 869\u001b[0m         k: \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwith_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwith_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatched\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdrop_last_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_last_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremove_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_in_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m            \u001b[49m\u001b[43mload_from_cache_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_from_cache_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_file_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_file_names\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwriter_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdisable_nullable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_nullable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfn_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    888\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, dataset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    889\u001b[0m     }\n\u001b[1;32m    890\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/acobur/lib/python3.12/site-packages/datasets/arrow_dataset.py:593\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    591\u001b[0m     \u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    592\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 593\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    594\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/acobur/lib/python3.12/site-packages/datasets/arrow_dataset.py:558\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    552\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[1;32m    553\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[1;32m    555\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[1;32m    556\u001b[0m }\n\u001b[1;32m    557\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 558\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    559\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    560\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/acobur/lib/python3.12/site-packages/datasets/arrow_dataset.py:3105\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transformed_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3100\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hf_tqdm(\n\u001b[1;32m   3101\u001b[0m         unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m examples\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3102\u001b[0m         total\u001b[38;5;241m=\u001b[39mpbar_total,\n\u001b[1;32m   3103\u001b[0m         desc\u001b[38;5;241m=\u001b[39mdesc \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMap\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   3104\u001b[0m     ) \u001b[38;5;28;01mas\u001b[39;00m pbar:\n\u001b[0;32m-> 3105\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_single\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdataset_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   3106\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdone\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   3107\u001b[0m \u001b[43m                \u001b[49m\u001b[43mshards_done\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/acobur/lib/python3.12/site-packages/datasets/arrow_dataset.py:3482\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[1;32m   3478\u001b[0m indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m   3479\u001b[0m     \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mslice\u001b[39m(i, i \u001b[38;5;241m+\u001b[39m batch_size)\u001b[38;5;241m.\u001b[39mindices(shard\u001b[38;5;241m.\u001b[39mnum_rows)))\n\u001b[1;32m   3480\u001b[0m )  \u001b[38;5;66;03m# Something simpler?\u001b[39;00m\n\u001b[1;32m   3481\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3482\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[43mapply_function_on_filtered_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3485\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_same_num_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mshard\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_indexes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3486\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3487\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3488\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m NumExamplesMismatchError:\n\u001b[1;32m   3489\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetTransformationNotAllowedError(\n\u001b[1;32m   3490\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `.map` in batched mode on a dataset with attached indexes is allowed only if it doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt create or remove existing examples. You can first run `.drop_index() to remove your index and then re-add it.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3491\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/acobur/lib/python3.12/site-packages/datasets/arrow_dataset.py:3361\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[0;34m(pa_inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_rank:\n\u001b[1;32m   3360\u001b[0m     additional_args \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (rank,)\n\u001b[0;32m-> 3361\u001b[0m processed_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3362\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed_inputs, LazyDict):\n\u001b[1;32m   3363\u001b[0m     processed_inputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   3364\u001b[0m         k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m processed_inputs\u001b[38;5;241m.\u001b[39mkeys_to_format\n\u001b[1;32m   3365\u001b[0m     }\n",
      "Cell \u001b[0;32mIn[99], line 17\u001b[0m, in \u001b[0;36mclean_text\u001b[0;34m(sentence_batch)\u001b[0m\n\u001b[1;32m     14\u001b[0m text \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m@\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+|\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m#\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, text)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Elimina los caracteres de puntuación\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[43mstrip_punctuation\u001b[49m(text)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Elimina los números\u001b[39;00m\n\u001b[1;32m     20\u001b[0m text \u001b[38;5;241m=\u001b[39m strip_numeric(text)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'strip_punctuation' is not defined"
     ]
    }
   ],
   "source": [
    "sentences_corpus = dataset_dict.map(clean_text, batched = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45965bc-a9b3-4372-8b11-001af10d255e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
